
# Projeto Data Lake Moderno: Bronze â†’ Silver â†’ Gold

> Estrutura inicial do projeto para ingestÃ£o, processamento e disponibilizaÃ§Ã£o de dados em ambiente Kubernetes, com Spark, MinIO, Airflow e GitOps.

## ğŸ“ Estrutura Organizada

```
mudar-depois/
â”œâ”€â”€ src/                          # CÃ³digo fonte
â”‚   â”œâ”€â”€ core/                     # Scripts principais
â”‚   â”‚   â””â”€â”€ bronze_ingestion.py   # Pipeline Bronze
â”‚   â”œâ”€â”€ pipelines/                # Scripts de processamento
â”‚   â”‚   â”œâ”€â”€ test_bronze_ingestion.sh
â”‚   â”‚   â”œâ”€â”€ test_local_ingestion.py
â”‚   â”‚   â””â”€â”€ test_silver_transformation.sh
â”‚   â””â”€â”€ dags/                     # DAGs do Airflow
â”‚       â”œâ”€â”€ bronze_ingestion_dag.py
â”‚       â””â”€â”€ catfacts_silver_transformation_dag.py
â”œâ”€â”€ config/                       # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ .env.example              # Exemplo de variÃ¡veis
â”‚   â”œâ”€â”€ requirements.txt          # DependÃªncias Python
â”‚   â””â”€â”€ infra/                    # ConfiguraÃ§Ãµes K8s
â”‚       â”œâ”€â”€ namespace.yaml
â”‚       â”œâ”€â”€ minio-deployment.yaml
â”‚       â”œâ”€â”€ airflow-deployment.yaml
â”‚       â”œâ”€â”€ secrets.yaml
â”‚       â””â”€â”€ deploy.sh
â”œâ”€â”€ data/                         # Dados (Bronze/Silver/Gold)
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â”œâ”€â”€ scripts/                      # Scripts utilitÃ¡rios
â”‚   â””â”€â”€ check_dependencies.sh
â”œâ”€â”€ docs/                         # DocumentaÃ§Ã£o
â”‚   â””â”€â”€ INSTALL.md
â”œâ”€â”€ tests/                        # Testes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ .venv/                        # Ambiente virtual (opcional)
```

## DescriÃ§Ã£o das pastas
- **infra/**: Arquivos de configuraÃ§Ã£o e manifestos para infraestrutura (Kubernetes, MinIO, Airflow, etc).
- **pipelines/**: Scripts e notebooks de processamento de dados (ETL/ELT com Spark).
- **dags/**: DAGs do Airflow para orquestraÃ§Ã£o dos pipelines.
- **data/**: Dados organizados nas camadas Bronze (ingestÃ£o), Silver (limpeza/transformaÃ§Ã£o) e Gold (dados prontos para consumo).
- **tests/**: Testes unitÃ¡rios e de integraÃ§Ã£o para garantir qualidade dos pipelines e infraestrutura.
- **docs/**: DocumentaÃ§Ã£o tÃ©cnica, diagramas e exemplos de uso.
- **.gitignore**: Evita versionar dados sensÃ­veis, arquivos temporÃ¡rios e ambientes locais.

## Como validar a estrutura
1. Verifique se todos os diretÃ³rios foram criados:
	```bash
	tree -L 2
	```
2. Confira se o `.gitignore` estÃ¡ presente e correto.
3. Leia este README para entender o propÃ³sito de cada pasta.

## Etapa 2: Ambiente Kubernetes + MinIO + Airflow

### O que foi implementado
- **Namespace**: `data-lake` para isolamento.
- **MinIO**: Object storage para camadas Bronze/Silver/Gold.
- **Airflow**: OrquestraÃ§Ã£o de pipelines com Postgres como DB.
- **Secrets e ConfigMaps**: Para credenciais e configuraÃ§Ãµes.
- **Resources**: Limits e requests para evitar conflitos de recursos.
- **Script de deploy**: Automatiza a aplicaÃ§Ã£o no cluster.

### Boas prÃ¡ticas aplicadas
- SeguranÃ§a: Credenciais em Secrets (base64 encoded).
- Escalabilidade: Replicas configurÃ¡veis, volumes persistentes simulados.
- Observabilidade: Logs via kubectl, health checks implÃ­citos.
- GitOps-ready: Manifestos versionados para integraÃ§Ã£o com ArgoCD/Flux.

### Como executar
1. Certifique-se de ter um cluster Kubernetes (minikube, kind ou cloud).
2. Execute o script de deploy:
   ```bash
   cd infra
   ./deploy.sh
   ```

### Como validar
1. Verifique os pods:
   ```bash
   kubectl get pods -n data-lake
   ```
   Deve mostrar: minio, postgres, airflow-webserver, airflow-scheduler (todos Running).

2. Verifique os serviÃ§os:
   ```bash
   kubectl get services -n data-lake
   ```
   MinIO: ClusterIP na porta 9000, Airflow: LoadBalancer na porta 8080.

3. Acesse Airflow (porta-forward se necessÃ¡rio):
   ```bash
   kubectl port-forward svc/airflow-webserver-service 8080:8080 -n data-lake
   ```
   Abra http://localhost:8080 (user: admin, pass: admin).

4. Teste MinIO (porta-forward):
   ```bash
   kubectl port-forward svc/minio-service 9000:9000 -n data-lake
   ```
   Abra http://localhost:9000 (use credenciais do ConfigMap).

## Etapa 3: Pipeline de IngestÃ£o (Camada Bronze)

### O que foi implementado
- **Script PySpark**: `pipelines/bronze_ingestion.py` - Extrai dados de API (ex: JSONPlaceholder) e salva no MinIO.
- **DAG Airflow**: `dags/bronze_ingestion_dag.py` - Orquestra a execuÃ§Ã£o diÃ¡ria.
- **Script de teste**: `pipelines/test_bronze_ingestion.sh` - Para testar localmente.

### Boas prÃ¡ticas aplicadas (Airflow 2.x)
- **TaskFlow API**: Uso de `@task` decorators para cÃ³digo mais limpo e legÃ­vel
- **Dag Decorator**: DAG definida como funÃ§Ã£o decorada com `@dag`
- **Tipagem e validaÃ§Ã£o**: ValidaÃ§Ã£o de dados entre tarefas
- **XCom automÃ¡tico**: Passagem de dados entre tarefas via return
- **Tags**: OrganizaÃ§Ã£o com tags ['bronze', 'ingestion', 'catfacts', 'api']
- **Execution timeout**: Timeout de 1 hora para evitar execuÃ§Ãµes infinitas
- **Retries aumentado**: 3 tentativas com delay de 5 minutos
- **Schedule moderno**: Uso de '@daily' ao invÃ©s de timedelta
- **Docstrings**: DocumentaÃ§Ã£o completa das funÃ§Ãµes e DAG

### Como executar
1. **Via Airflow (produÃ§Ã£o)**:
   - Copie o DAG para o pod do Airflow:
     ```bash
     kubectl cp dags/catfacts_bronze_ingestion_dag.py data-lake/airflow-webserver-xxx:/opt/airflow/dags/
     ```
   - Acesse Airflow UI e ative o DAG `catfacts_bronze_ingestion_dag`.

2. **Teste local (desenvolvimento)**:
   - Configure MinIO local (porta-forward):
     ```bash
     kubectl port-forward svc/minio-service 9000:9000 -n data-lake
     ```
   - Execute: `./pipelines/test_bronze_ingestion.sh`

### Como validar
1. Verifique logs no Airflow ou console.
2. Acesse MinIO UI (porta 9000) e confira o bucket `bronze-landing` com arquivo `catfacts_batch_YYYY-MM-DD.json`.
3. ConteÃºdo do arquivo deve ter dados JSON com campos como `fact`, `length`, etc., mais `ingestion_timestamp`.

### Observabilidade implementada
- **Logs por hora**: Cada tarefa imprime timestamp e status com emojis
- **MÃ©tricas**: Contagem de registros processados
- **ValidaÃ§Ã£o**: VerificaÃ§Ã£o de campos obrigatÃ³rios
- **EstatÃ­sticas**: DistribuiÃ§Ã£o por categoria na Silver

### Exemplo de output esperado
```
[2025-09-02 14:30:15] ğŸš€ Iniciando extraÃ§Ã£o de dados da API CatFacts...
[2025-09-02 14:30:16] âœ… ExtraÃ­dos 10 fatos sobre gatos da API
[2025-09-02 14:30:17] ğŸ” Iniciando validaÃ§Ã£o dos dados...
[2025-09-02 14:30:17] âœ… Dados validados: 10 registros com campos obrigatÃ³rios
[2025-09-02 14:30:18] ğŸ’¾ Iniciando salvamento na camada Bronze...
[2025-09-02 14:30:20] âœ… Dados salvos em: s3a://bronze-landing/catfacts_batch_2025-09-02.json
[2025-09-02 14:30:20] ğŸ“Š Total processado: 10 fatos sobre gatos
```

### PrÃ³ximos passos
- Executar DAGs no Airflow
- Criar pipeline de transformaÃ§Ã£o Silver (jÃ¡ implementado em `dags/catfacts_silver_transformation_dag.py`)
- Adicionar testes automatizados
- Implementar observabilidade (logs, mÃ©tricas, alertas)

---
> DAGs seguem as melhores prÃ¡ticas do Airflow 2.x: TaskFlow API, validaÃ§Ã£o de dados, tipagem e documentaÃ§Ã£o completa.

## ğŸ“‹ DependÃªncias Verificadas âœ…

### Sistema
- âœ… **Python 3.12.3** - Linguagem principal
- âœ… **OpenJDK 11** - NecessÃ¡rio para PySpark
- âœ… **pip 24.0** - Gerenciador de pacotes
- âœ… **Docker** - Para serviÃ§os locais (MinIO, etc.)
- âœ… **kubectl** - Para Kubernetes (opcional)

### Python Packages
- âœ… **requests** - Para chamadas de API
- âœ… **boto3** - Para integraÃ§Ã£o com MinIO/S3
- âœ… **pyspark** - Para processamento distribuÃ­do

### Arquivos de ConfiguraÃ§Ã£o
- ğŸ“„ `config/requirements.txt` - Lista completa de dependÃªncias
- ğŸ“„ `docs/INSTALL.md` - Guia detalhado de instalaÃ§Ã£o
- ğŸ“„ `config/.env.example` - Exemplo de variÃ¡veis de ambiente
- ğŸ› ï¸ `scripts/check_dependencies.sh` - Script de verificaÃ§Ã£o automÃ¡tica

### Como Usar
1. **Copie o arquivo de configuraÃ§Ã£o:**
   ```bash
   cp config/.env.example .env
   ```

2. **Configure as variÃ¡veis no `.env`** conforme seu ambiente

3. **Execute a verificaÃ§Ã£o:**
   ```bash
   ./scripts/check_dependencies.sh
   ```

### PrÃ³ximos Passos
- Configurar MinIO local ou cluster Kubernetes
- Executar pipelines de teste
- Desenvolver camadas Silver e Gold
