
# Projeto Data Lake Moderno: Bronze ‚Üí Silver ‚Üí Gold

> Estrutura inicial do projeto para ingest√£o, processamento e disponibiliza√ß√£o de dados em ambiente Kubernetes, com Spark, MinIO, Airflow e GitOps.

## Estrutura de diret√≥rios
```
.
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ infra/           # Infraestrutura (K8s, MinIO, Airflow, configs)
‚îú‚îÄ‚îÄ pipelines/       # Pipelines ETL/ELT (Spark, scripts)
‚îú‚îÄ‚îÄ dags/            # DAGs do Airflow
‚îú‚îÄ‚îÄ data/            # Dados brutos e processados (Bronze/Silver/Gold)
‚îÇ   ‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îî‚îÄ‚îÄ gold/
‚îú‚îÄ‚îÄ tests/           # Testes automatizados
‚îú‚îÄ‚îÄ docs/            # Documenta√ß√£o adicional
‚îî‚îÄ‚îÄ .gitignore
```

## Descri√ß√£o das pastas
- **infra/**: Arquivos de configura√ß√£o e manifestos para infraestrutura (Kubernetes, MinIO, Airflow, etc).
- **pipelines/**: Scripts e notebooks de processamento de dados (ETL/ELT com Spark).
- **dags/**: DAGs do Airflow para orquestra√ß√£o dos pipelines.
- **data/**: Dados organizados nas camadas Bronze (ingest√£o), Silver (limpeza/transforma√ß√£o) e Gold (dados prontos para consumo).
- **tests/**: Testes unit√°rios e de integra√ß√£o para garantir qualidade dos pipelines e infraestrutura.
- **docs/**: Documenta√ß√£o t√©cnica, diagramas e exemplos de uso.
- **.gitignore**: Evita versionar dados sens√≠veis, arquivos tempor√°rios e ambientes locais.

## Como validar a estrutura
1. Verifique se todos os diret√≥rios foram criados:
	```bash
	tree -L 2
	```
2. Confira se o `.gitignore` est√° presente e correto.
3. Leia este README para entender o prop√≥sito de cada pasta.

## Etapa 2: Ambiente Kubernetes + MinIO + Airflow

### O que foi implementado
- **Namespace**: `data-lake` para isolamento.
- **MinIO**: Object storage para camadas Bronze/Silver/Gold.
- **Airflow**: Orquestra√ß√£o de pipelines com Postgres como DB.
- **Secrets e ConfigMaps**: Para credenciais e configura√ß√µes.
- **Resources**: Limits e requests para evitar conflitos de recursos.
- **Script de deploy**: Automatiza a aplica√ß√£o no cluster.

### Boas pr√°ticas aplicadas
- Seguran√ßa: Credenciais em Secrets (base64 encoded).
- Escalabilidade: Replicas configur√°veis, volumes persistentes simulados.
- Observabilidade: Logs via kubectl, health checks impl√≠citos.
- GitOps-ready: Manifestos versionados para integra√ß√£o com ArgoCD/Flux.

### Como executar
1. Certifique-se de ter um cluster Kubernetes (minikube, kind ou cloud).
2. Execute o script de deploy:
   ```bash
   cd infra
   ./deploy.sh
   ```

### Como validar
1. Verifique os pods:
   ```bash
   kubectl get pods -n data-lake
   ```
   Deve mostrar: minio, postgres, airflow-webserver, airflow-scheduler (todos Running).

2. Verifique os servi√ßos:
   ```bash
   kubectl get services -n data-lake
   ```
   MinIO: ClusterIP na porta 9000, Airflow: LoadBalancer na porta 8080.

3. Acesse Airflow (porta-forward se necess√°rio):
   ```bash
   kubectl port-forward svc/airflow-webserver-service 8080:8080 -n data-lake
   ```
   Abra http://localhost:8080 (user: admin, pass: admin).

4. Teste MinIO (porta-forward):
   ```bash
   kubectl port-forward svc/minio-service 9000:9000 -n data-lake
   ```
   Abra http://localhost:9000 (use credenciais do ConfigMap).

## Etapa 3: Pipeline de Ingest√£o (Camada Bronze)

### O que foi implementado
- **Script PySpark**: `pipelines/bronze_ingestion.py` - Extrai dados de API (ex: JSONPlaceholder) e salva no MinIO.
- **DAG Airflow**: `dags/bronze_ingestion_dag.py` - Orquestra a execu√ß√£o di√°ria.
- **Script de teste**: `pipelines/test_bronze_ingestion.sh` - Para testar localmente.

### Boas pr√°ticas aplicadas (Airflow 2.x)
- **TaskFlow API**: Uso de `@task` decorators para c√≥digo mais limpo e leg√≠vel
- **Dag Decorator**: DAG definida como fun√ß√£o decorada com `@dag`
- **Tipagem e valida√ß√£o**: Valida√ß√£o de dados entre tarefas
- **XCom autom√°tico**: Passagem de dados entre tarefas via return
- **Tags**: Organiza√ß√£o com tags ['bronze', 'ingestion', 'catfacts', 'api']
- **Execution timeout**: Timeout de 1 hora para evitar execu√ß√µes infinitas
- **Retries aumentado**: 3 tentativas com delay de 5 minutos
- **Schedule moderno**: Uso de '@daily' ao inv√©s de timedelta
- **Docstrings**: Documenta√ß√£o completa das fun√ß√µes e DAG

### Como executar
1. **Via Airflow (produ√ß√£o)**:
   - Copie o DAG para o pod do Airflow:
     ```bash
     kubectl cp dags/catfacts_bronze_ingestion_dag.py data-lake/airflow-webserver-xxx:/opt/airflow/dags/
     ```
   - Acesse Airflow UI e ative o DAG `catfacts_bronze_ingestion_dag`.

2. **Teste local (desenvolvimento)**:
   - Configure MinIO local (porta-forward):
     ```bash
     kubectl port-forward svc/minio-service 9000:9000 -n data-lake
     ```
   - Execute: `./pipelines/test_bronze_ingestion.sh`

### Como validar
1. Verifique logs no Airflow ou console.
2. Acesse MinIO UI (porta 9000) e confira o bucket `bronze-landing` com arquivo `catfacts_batch_YYYY-MM-DD.json`.
3. Conte√∫do do arquivo deve ter dados JSON com campos como `fact`, `length`, etc., mais `ingestion_timestamp`.

### Observabilidade implementada
- **Logs por hora**: Cada tarefa imprime timestamp e status com emojis
- **M√©tricas**: Contagem de registros processados
- **Valida√ß√£o**: Verifica√ß√£o de campos obrigat√≥rios
- **Estat√≠sticas**: Distribui√ß√£o por categoria na Silver

### Exemplo de output esperado
```
[2025-09-02 14:30:15] üöÄ Iniciando extra√ß√£o de dados da API CatFacts...
[2025-09-02 14:30:16] ‚úÖ Extra√≠dos 10 fatos sobre gatos da API
[2025-09-02 14:30:17] üîç Iniciando valida√ß√£o dos dados...
[2025-09-02 14:30:17] ‚úÖ Dados validados: 10 registros com campos obrigat√≥rios
[2025-09-02 14:30:18] üíæ Iniciando salvamento na camada Bronze...
[2025-09-02 14:30:20] ‚úÖ Dados salvos em: s3a://bronze-landing/catfacts_batch_2025-09-02.json
[2025-09-02 14:30:20] üìä Total processado: 10 fatos sobre gatos
```

### Pr√≥ximos passos
- Executar DAGs no Airflow
- Criar pipeline de transforma√ß√£o Silver (j√° implementado em `dags/catfacts_silver_transformation_dag.py`)
- Adicionar testes automatizados
- Implementar observabilidade (logs, m√©tricas, alertas)

---
> DAGs seguem as melhores pr√°ticas do Airflow 2.x: TaskFlow API, valida√ß√£o de dados, tipagem e documenta√ß√£o completa.
